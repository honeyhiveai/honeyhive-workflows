# Data Plane Deployment Configuration
# Compute workloads and processing

# Core Configuration
org: honeyhive
env: prod
region: us-east-1
sregion: use1
deployment: compute-01
account_id: "987654321098"

# CRITICAL: Set deployment type
deployment_type: data_plane

# Networking Configuration - larger for compute
vpc_cidr: 10.200.0.0/16
availability_zones:
  - us-east-1a
  - us-east-1b
  - us-east-1c
nat_gateway_count: 1  # Cost optimization for data plane
enable_vpc_endpoints: false  # Minimal endpoints

# Larger subnets for compute workloads
public_subnet_cidrs:
  - 10.200.1.0/24
  - 10.200.2.0/24
  - 10.200.3.0/24
private_subnet_cidrs:
  - 10.200.10.0/22  # /22 for more IPs
  - 10.200.14.0/22
  - 10.200.18.0/22

# DNS Configuration
domain_name: compute.honeyhive.ai
shortname: comp
dns_zone_name: compute-01.use1.prod.comp.compute.honeyhive.ai

# EKS Configuration - optimized for compute
eks_version: "1.31"
cluster_endpoint_private_access: true
cluster_endpoint_public_access: false

# Node configuration - auto-scaling for compute
node_instance_types:
  - c6i.2xlarge   # Compute optimized
  - c6i.4xlarge
  - c6i.8xlarge
node_min_size: 1
node_max_size: 100  # Scale big
node_desired_size: 3

# Karpenter configuration for data plane
karpenter:
  enabled: true  # Critical for data plane
  provisioners:
    - name: compute-general
      instance_types:
        - c6i.2xlarge
        - c6i.4xlarge
        - m6i.2xlarge
        - m6i.4xlarge
      capacity_type: spot  # Use spot for cost savings
      
    - name: compute-memory
      instance_types:
        - r6i.2xlarge
        - r6i.4xlarge
        - r6i.8xlarge
      capacity_type: on-demand
      taints:
        - key: workload-type
          value: memory-intensive
          effect: NoSchedule
          
    - name: compute-gpu
      instance_types:
        - g4dn.xlarge
        - g4dn.2xlarge
        - g4dn.4xlarge
      capacity_type: on-demand
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule

# Data Plane Features (auto-set by deployment_type)
# - monitoring: false (ships to control plane)
# - argocd: false (managed by control plane)
# - eso: true (get secrets from control)
# - observability: true (local collection)
# - backup: false (stateless)
# - karpenter: true (critical for scaling)

# S3 Configuration (temporary storage)
s3_versioning: false  # Not needed for temp data
s3_lifecycle_rules:
  - id: cleanup-temp
    status: enabled
    expiration_days: 7

# Batch compute configuration (optional)
batch_compute:
  enabled: true
  compute_environments:
    - name: batch-spot
      type: managed
      state: enabled
      compute_type: spot
      max_vcpus: 256
      
    - name: batch-ondemand
      type: managed
      state: enabled
      compute_type: on-demand
      max_vcpus: 128

# GPU support configuration (optional)
gpu_support:
  enabled: true
  nvidia_device_plugin: true
  gpu_operator: true

# Observability - ships to control plane
observability:
  metrics:
    prometheus_remote_write:
      endpoint: https://control.honeyhive.ai/prometheus/write
      auth_type: sigv4
  logs:
    fluent_bit:
      output: kinesis_firehose
      delivery_stream: control-plane-logs
  traces:
    opentelemetry:
      endpoint: control.honeyhive.ai:4317
      protocol: grpc

# Connection to control plane
control_plane:
  endpoint: https://api.control.honeyhive.ai
  region: us-west-2
  auth_type: iam_role
